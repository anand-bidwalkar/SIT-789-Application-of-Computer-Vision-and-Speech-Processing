# -*- coding: utf-8 -*-
"""Task-5.2 HD Mask RCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BoGkYqldc-U7Bb78Oxh-s5EY13XyPQnF

# SIT-789 Task-5.2 HD Mask R-CNN Implementation

## Install and load libraries
"""

! git clone https://github.com/akTwelve/Mask_RCNN.git

!pip install tensorflow

import tensorflow

print(tensorflow.__version__)

import os
os.chdir('Mask_RCNN/samples')

# Commented out IPython magic to ensure Python compatibility.
import os
import sys
import random
import math
import numpy as np
import skimage.io
import matplotlib
import matplotlib.pyplot as plt

# Root directory of the project
ROOT_DIR = os.path.abspath("../")

# Import Mask RCNN
sys.path.append(ROOT_DIR)  # To find local version of the library
from mrcnn import utils
import mrcnn.model as modellib
from mrcnn import visualize
# Import COCO config
sys.path.append(os.path.join(ROOT_DIR, "samples/coco/"))  # To find local version
import coco

# %matplotlib inline 

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "logs")

# Local path to trained weights file
COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")
# Download COCO trained weights from Releases if needed
if not os.path.exists(COCO_MODEL_PATH):
    utils.download_trained_weights(COCO_MODEL_PATH)

# Directory of images to run detection on
IMAGE_DIR = os.path.join(ROOT_DIR, "images")

"""## Configurations

We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.

For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change.
"""

class InferenceConfig(coco.CocoConfig):
    # Set batch size to 1 since we'll be running inference on
    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

config = InferenceConfig()
config.display()

"""## Create Model and Load Trained Weights"""

# Create model object in inference mode.
model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)

# Load weights trained on MS-COCO
model.load_weights(COCO_MODEL_PATH, by_name=True)

"""## Class Names"""

# COCO Class names
# Index of the class in the list is its ID. For example, to get ID of
# the teddy bear class, use: class_names.index('teddy bear')
class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']

"""## Run Object Detection"""

def display_orig_image(file_name):
  image = skimage.io.imread(file_name)
  plt.figure(figsize=(12,10))
  skimage.io.imshow(image)
  return image

image = display_orig_image(os.path.join(IMAGE_DIR, '3862500489_6fd195d183_z.jpg'))

def detect_instances(image):
  # Run detection
  results = model.detect([image], verbose=1)
  # Visualize results
  r = results[0]

  print("rois",r['rois'].shape)
  print("class_ids",r['class_ids'], len(r['class_ids']))
  print("masks",r['masks'].shape)
  print("scores",r['scores'])

  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                              class_names, r['scores'])
  return r
  
r = detect_instances(image)

"""Visualise individual objects detected by the Mask R-CNN model in the image"""

mask = r['masks']
mask = mask.astype(int)
mask.shape

for i in range(mask.shape[2]):
    temp = skimage.io.imread(os.path.join(IMAGE_DIR, '3862500489_6fd195d183_z.jpg'))
    for j in range(temp.shape[2]):
        temp[:,:,j] = temp[:,:,j] * mask[:,:,i]
    plt.figure(figsize=(8,8))
    plt.imshow(temp)

"""## Detect objects in all the sample images"""

file_names = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR)]
for file_name in file_names:
  image = display_orig_image(file_name)
  result = detect_instances(image)

"""## Human Pose Estimation

Clone repository for the human pose estimation code
"""

! git clone https://github.com/Superlee506/Mask_RCNN_Humanpose.git

"""This code works on the older version of the Tensorflow, Keras, Scipy"""

!pip install tensorflow==1.3
!pip install keras==2.0.8
!pip install scipy==1.1.0

import os
os.chdir('Mask_RCNN_Humanpose')

"""Download the model trained weight from the Github release for the human pose estimation on the COCO dataset"""

import shutil
import urllib.request
ROOT_DIR = os.getcwd()
COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5")
COCO_MODEL_URL = "https://github.com/Superlee506/Mask_RCNN_Humanpose/releases/download/v0.9-alpha/mask_rcnn_coco_humanpose.h5"
with urllib.request.urlopen(COCO_MODEL_URL) as resp, open(COCO_MODEL_PATH, 'wb') as out:
        shutil.copyfileobj(resp, out)

# Commented out IPython magic to ensure Python compatibility.
import os
import sys
import random
import math
import numpy as np
import skimage.io
import matplotlib
import matplotlib.pyplot as plt

import coco
import utils
import model as modellib
import visualize
from model import log

# %matplotlib inline 

# Root directory of the project
ROOT_DIR = os.getcwd()

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "mylogs")

# Local path to trained weights file
COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5")
# Download COCO trained weights from Releases if needed
if not os.path.exists(COCO_MODEL_PATH):
    utils.download_trained_weights(COCO_MODEL_PATH)

# Directory of images to run detection on
COCO_DIR = "D:/Github/FastMaskRCNN/data/coco"  # TODO: enter value here
IMAGE_DIR = os.path.join(ROOT_DIR, "images")

class InferenceConfig(coco.CocoConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    KEYPOINT_MASK_POOL_SIZE = 7

inference_config = InferenceConfig()

# Recreate the model in inference mode
model = modellib.MaskRCNN(mode="inference", 
                          config=inference_config,
                          model_dir=MODEL_DIR)

# Get path to saved weights

model_path = os.path.join(ROOT_DIR, "mask_rcnn_coco_humanpose.h5")
assert model_path != "", "Provide path to trained weights"
print("Loading weights from ", model_path)
model.load_weights(model_path, by_name=True)

# COCO Class names
# Index of the class in the list is its ID. For example, to get ID of
# the teddy bear class, use: class_names.index('teddy bear')
class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']

IMAGE_DIR = os.path.join(ROOT_DIR, "pictures")

import cv2

file_names = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR)]
for file_name in file_names:
  print(file_name)
  image = cv2.imread(file_name)
  #BGR->RGB
  image = image[:,:,::-1]

  # Run detection
  results = model.detect_keypoint([image], verbose=1)
  r = results[0] # for one image

  log("rois",r['rois'])
  log("keypoints",r['keypoints'])
  log("class_ids",r['class_ids'])
  log("keypoints",r['keypoints'])
  log("masks",r['masks'])
  log("scores",r['scores'])

  visualize.display_keypoints(image,r['rois'],r['keypoints'],r['class_ids'],class_names,skeleton = inference_config.LIMBS)
  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                              class_names, r['scores'])