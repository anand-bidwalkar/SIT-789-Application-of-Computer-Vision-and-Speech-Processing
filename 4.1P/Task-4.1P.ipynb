{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIT789 Task-4.1 P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self, name, img_filenames, num_words):\n",
    "        self.name = name #name of your dictionary\n",
    "        self.img_filenames = img_filenames #list of image filenames\n",
    "        self.num_words = num_words #the number of words\n",
    "        self.training_data = [] #this is the training data required by the K-Means algorithm\n",
    "        self.words = [] #list of words, which are the centroids of clusters\n",
    "    \n",
    "    def learn(self):\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        num_keypoints = [] #this is used to store the number of keypoints in each image\n",
    "        #load training images and compute SIFT descriptors\n",
    "        for filename in self.img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            list_des = sift.detectAndCompute(img_gray, None)[1]\n",
    "            if list_des is None:\n",
    "                num_keypoints.append(0)\n",
    "            else:\n",
    "                num_keypoints.append(len(list_des))\n",
    "                for des in list_des:\n",
    "                    self.training_data.append(des)\n",
    "\n",
    "        #cluster SIFT descriptors using K-means algorithm\n",
    "        kmeans = KMeans(self.num_words)\n",
    "        kmeans.fit(self.training_data)\n",
    "        self.words = kmeans.cluster_centers_\n",
    "        #create word histograms for training images\n",
    "        training_word_histograms = [] #list of word histograms of all training images\n",
    "        index = 0\n",
    "        for i in range(0, len(self.img_filenames)):\n",
    "            #for each file, create a histogram\n",
    "            histogram = np.zeros(self.num_words, np.float32)\n",
    "            #if some keypoints exist\n",
    "            if num_keypoints[i] > 0:\n",
    "                for j in range(0, num_keypoints[i]):\n",
    "                    histogram[kmeans.labels_[j + index]] += 1\n",
    "                index += num_keypoints[i]\n",
    "                histogram /= num_keypoints[i]\n",
    "                training_word_histograms.append(histogram)\n",
    "                    \n",
    "        return training_word_histograms\n",
    "    \n",
    "    def create_word_histograms(self, img_filenames):\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        histograms = []\n",
    "        for filename in img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            descriptors = sift.detectAndCompute(img_gray, None)[1]\n",
    "\n",
    "            histogram = np.zeros(self.num_words, np.float32) #word histogram for the input image\n",
    "            if descriptors is not None:\n",
    "                for des in descriptors:\n",
    "                    #find the best matching word\n",
    "                    min_distance = 1111111 #this can be any large number\n",
    "                    matching_word_ID = -1 #initial matching_word_ID=-1 means no matching\n",
    "                    for i in range(0, self.num_words): #search for the best matching word\n",
    "                        distance = np.linalg.norm(des - self.words[i])\n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            matching_word_ID = i\n",
    "                    histogram[matching_word_ID] += 1\n",
    "                histogram /= len(descriptors) #normalise histogram to frequencies\n",
    "            histograms.append(histogram)\n",
    "        return histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FoodImages/Train/Cakes/cake1.png', 'FoodImages/Train/Cakes/cake10.jpg', 'FoodImages/Train/Cakes/cake11.jpg', 'FoodImages/Train/Cakes/cake12.jpg', 'FoodImages/Train/Cakes/cake13.jpg', 'FoodImages/Train/Cakes/cake14.jpg', 'FoodImages/Train/Cakes/cake15.jpg', 'FoodImages/Train/Cakes/cake16.jpg', 'FoodImages/Train/Cakes/cake17.jpg', 'FoodImages/Train/Cakes/cake18.jpg', 'FoodImages/Train/Cakes/cake19.jpg', 'FoodImages/Train/Cakes/cake2.png', 'FoodImages/Train/Cakes/cake20.jpg', 'FoodImages/Train/Cakes/cake21.jpg', 'FoodImages/Train/Cakes/cake22.jpg', 'FoodImages/Train/Cakes/cake23.jpg', 'FoodImages/Train/Cakes/cake24.jpg', 'FoodImages/Train/Cakes/cake25.jpg', 'FoodImages/Train/Cakes/cake26.jpg', 'FoodImages/Train/Cakes/cake27.jpg', 'FoodImages/Train/Cakes/cake28.jpg', 'FoodImages/Train/Cakes/cake29.jpg', 'FoodImages/Train/Cakes/cake3.png', 'FoodImages/Train/Cakes/cake30.jpg', 'FoodImages/Train/Cakes/cake4.jpg', 'FoodImages/Train/Cakes/cake5.jpg', 'FoodImages/Train/Cakes/cake6.jpg', 'FoodImages/Train/Cakes/cake7.jpg', 'FoodImages/Train/Cakes/cake8.jpg', 'FoodImages/Train/Cakes/cake9.jpg', 'FoodImages/Train/Pasta/pasta1.jpg', 'FoodImages/Train/Pasta/pasta10.jpg', 'FoodImages/Train/Pasta/pasta11.jpg', 'FoodImages/Train/Pasta/pasta12.jpg', 'FoodImages/Train/Pasta/pasta13.jpg', 'FoodImages/Train/Pasta/pasta14.jpg', 'FoodImages/Train/Pasta/pasta15.jpg', 'FoodImages/Train/Pasta/pasta16.jpg', 'FoodImages/Train/Pasta/pasta17.jpg', 'FoodImages/Train/Pasta/pasta18.jpg', 'FoodImages/Train/Pasta/pasta19.jpg', 'FoodImages/Train/Pasta/pasta2.jpg', 'FoodImages/Train/Pasta/pasta20.jpg', 'FoodImages/Train/Pasta/pasta21.png', 'FoodImages/Train/Pasta/pasta22.png', 'FoodImages/Train/Pasta/pasta23.png', 'FoodImages/Train/Pasta/pasta24.png', 'FoodImages/Train/Pasta/pasta25.png', 'FoodImages/Train/Pasta/pasta26.png', 'FoodImages/Train/Pasta/pasta27.png', 'FoodImages/Train/Pasta/pasta28.png', 'FoodImages/Train/Pasta/pasta29.jpg', 'FoodImages/Train/Pasta/pasta3.jpg', 'FoodImages/Train/Pasta/pasta30.jpg', 'FoodImages/Train/Pasta/pasta4.jpg', 'FoodImages/Train/Pasta/pasta5.jpg', 'FoodImages/Train/Pasta/pasta6.jpg', 'FoodImages/Train/Pasta/pasta7.jpg', 'FoodImages/Train/Pasta/pasta8.jpg', 'FoodImages/Train/Pasta/pasta9.jpg', 'FoodImages/Train/Pizza/pizza1.png', 'FoodImages/Train/Pizza/pizza10.jpg', 'FoodImages/Train/Pizza/pizza11.jpg', 'FoodImages/Train/Pizza/pizza12.jpg', 'FoodImages/Train/Pizza/pizza13.jpg', 'FoodImages/Train/Pizza/pizza14.jpg', 'FoodImages/Train/Pizza/pizza15.jpg', 'FoodImages/Train/Pizza/pizza16.jpg', 'FoodImages/Train/Pizza/pizza17.jpg', 'FoodImages/Train/Pizza/pizza18.jpg', 'FoodImages/Train/Pizza/pizza19.jpg', 'FoodImages/Train/Pizza/pizza2.jpg', 'FoodImages/Train/Pizza/pizza20.jpg', 'FoodImages/Train/Pizza/pizza21.jpg', 'FoodImages/Train/Pizza/pizza22.jpg', 'FoodImages/Train/Pizza/pizza23.jpg', 'FoodImages/Train/Pizza/pizza24.jpg', 'FoodImages/Train/Pizza/pizza25.jpg', 'FoodImages/Train/Pizza/pizza26.jpg', 'FoodImages/Train/Pizza/pizza27.jpg', 'FoodImages/Train/Pizza/pizza28.jpg', 'FoodImages/Train/Pizza/pizza29.jpg', 'FoodImages/Train/Pizza/pizza3.jpg', 'FoodImages/Train/Pizza/pizza30.jpg', 'FoodImages/Train/Pizza/pizza4.jpg', 'FoodImages/Train/Pizza/pizza5.jpg', 'FoodImages/Train/Pizza/pizza6.jpg', 'FoodImages/Train/Pizza/pizza7.jpg', 'FoodImages/Train/Pizza/pizza8.jpg', 'FoodImages/Train/Pizza/pizza9.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "foods = ['Cakes', 'Pasta', 'Pizza']\n",
    "path = 'FoodImages/'\n",
    "training_file_names = []\n",
    "training_food_labels = []\n",
    "\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Train/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    training_file_names += sub_file_names\n",
    "    training_food_labels += sub_food_labels\n",
    "\n",
    "print(training_file_names)\n",
    "print(training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50\n",
    "dictionary_name = 'food'\n",
    "dictionary = Dictionary(dictionary_name, training_file_names, num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_word_histograms = dictionary.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#save dictionary\n",
    "with open('food_dictionary.dic', 'wb') as f: #'wb' is for binary write\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #you may not need to import it if this has been done\n",
    "with open('food_dictionary.dic', 'rb') as f: #'rb' is for binary read\n",
    "    dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nearest_neighbours = 5 #number of neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food label:  [1]\n"
     ]
    }
   ],
   "source": [
    "test_file_names = ['FoodImages/Test/Pasta/pasta35.jpg']\n",
    "word_histograms = dictionary.create_word_histograms(test_file_names)\n",
    "predicted_food_labels = knn.predict(word_histograms)\n",
    "print('Food label: ', predicted_food_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FoodImages/Test/Cakes/cake31.jpg', 'FoodImages/Test/Cakes/cake32.jpg', 'FoodImages/Test/Cakes/cake33.jpg', 'FoodImages/Test/Cakes/cake34.jpg', 'FoodImages/Test/Cakes/cake35.jpg', 'FoodImages/Test/Cakes/cake36.jpg', 'FoodImages/Test/Cakes/cake37.jpg', 'FoodImages/Test/Cakes/cake38.jpg', 'FoodImages/Test/Cakes/cake39.jpg', 'FoodImages/Test/Cakes/cake40.jpg', 'FoodImages/Test/Cakes/cake41.jpg', 'FoodImages/Test/Cakes/cake42.jpg', 'FoodImages/Test/Cakes/cake43.jpg', 'FoodImages/Test/Cakes/cake44.jpg', 'FoodImages/Test/Cakes/cake45.jpg', 'FoodImages/Test/Cakes/cake46.jpg', 'FoodImages/Test/Cakes/cake47.jpg', 'FoodImages/Test/Cakes/cake48.jpg', 'FoodImages/Test/Cakes/cake49.jpg', 'FoodImages/Test/Cakes/cake50.jpg', 'FoodImages/Test/Cakes/cake51.jpg', 'FoodImages/Test/Cakes/cake52.jpg', 'FoodImages/Test/Cakes/cake53.jpg', 'FoodImages/Test/Cakes/cake54.jpg', 'FoodImages/Test/Cakes/cake55.jpg', 'FoodImages/Test/Cakes/cake56.jpg', 'FoodImages/Test/Cakes/cake57.jpg', 'FoodImages/Test/Cakes/cake58.jpg', 'FoodImages/Test/Cakes/cake59.jpg', 'FoodImages/Test/Cakes/cake60.jpg', 'FoodImages/Test/Pasta/pasta31.jpg', 'FoodImages/Test/Pasta/pasta32.jpg', 'FoodImages/Test/Pasta/pasta33.jpg', 'FoodImages/Test/Pasta/pasta34.jpg', 'FoodImages/Test/Pasta/pasta35.jpg', 'FoodImages/Test/Pasta/pasta36.jpg', 'FoodImages/Test/Pasta/pasta37.jpg', 'FoodImages/Test/Pasta/pasta38.jpg', 'FoodImages/Test/Pasta/pasta39.jpg', 'FoodImages/Test/Pasta/pasta40.jpg', 'FoodImages/Test/Pasta/pasta41.jpg', 'FoodImages/Test/Pasta/pasta42.jpg', 'FoodImages/Test/Pasta/pasta43.jpg', 'FoodImages/Test/Pasta/pasta44.jpg', 'FoodImages/Test/Pasta/pasta45.jpg', 'FoodImages/Test/Pasta/pasta46.jpg', 'FoodImages/Test/Pasta/pasta47.jpg', 'FoodImages/Test/Pasta/pasta48.jpg', 'FoodImages/Test/Pasta/pasta49.jpg', 'FoodImages/Test/Pasta/pasta50.jpg', 'FoodImages/Test/Pasta/pasta51.jpg', 'FoodImages/Test/Pasta/pasta52.jpg', 'FoodImages/Test/Pasta/pasta53.jpg', 'FoodImages/Test/Pasta/pasta54.jpg', 'FoodImages/Test/Pasta/pasta55.jpg', 'FoodImages/Test/Pasta/pasta56.jpg', 'FoodImages/Test/Pasta/pasta57.jpg', 'FoodImages/Test/Pasta/pasta58.jpg', 'FoodImages/Test/Pasta/pasta59.jpg', 'FoodImages/Test/Pasta/pasta60.jpg', 'FoodImages/Test/Pizza/pizza31.jpg', 'FoodImages/Test/Pizza/pizza32.jpg', 'FoodImages/Test/Pizza/pizza33.jpg', 'FoodImages/Test/Pizza/pizza34.jpg', 'FoodImages/Test/Pizza/pizza35.jpg', 'FoodImages/Test/Pizza/pizza36.jpg', 'FoodImages/Test/Pizza/pizza37.jpg', 'FoodImages/Test/Pizza/pizza38.jpg', 'FoodImages/Test/Pizza/pizza39.jpg', 'FoodImages/Test/Pizza/pizza40.jpg', 'FoodImages/Test/Pizza/pizza41.jpg', 'FoodImages/Test/Pizza/pizza42.jpg', 'FoodImages/Test/Pizza/pizza43.jpg', 'FoodImages/Test/Pizza/pizza44.jpg', 'FoodImages/Test/Pizza/pizza45.jpg', 'FoodImages/Test/Pizza/pizza46.jpg', 'FoodImages/Test/Pizza/pizza47.jpg', 'FoodImages/Test/Pizza/pizza48.jpg', 'FoodImages/Test/Pizza/pizza49.jpg', 'FoodImages/Test/Pizza/pizza50.jpg', 'FoodImages/Test/Pizza/pizza51.jpg', 'FoodImages/Test/Pizza/pizza52.jpg', 'FoodImages/Test/Pizza/pizza53.jpg', 'FoodImages/Test/Pizza/pizza54.jpg', 'FoodImages/Test/Pizza/pizza55.jpg', 'FoodImages/Test/Pizza/pizza56.jpg', 'FoodImages/Test/Pizza/pizza57.png', 'FoodImages/Test/Pizza/pizza58.png', 'FoodImages/Test/Pizza/pizza59.png', 'FoodImages/Test/Pizza/pizza60.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "test_file_names = []\n",
    "test_food_labels = []\n",
    "\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Test/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    test_file_names += sub_file_names\n",
    "    test_food_labels += sub_food_labels\n",
    "\n",
    "print(test_file_names)\n",
    "print(test_food_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted labels for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_labels(classifier):\n",
    "    predicted_food_labels = []\n",
    "    for file_name in test_file_names:\n",
    "        word_histograms = dictionary.create_word_histograms([file_name])\n",
    "        predicted_food_label = classifier.predict(word_histograms)\n",
    "        predicted_food_labels.append(predicted_food_label)\n",
    "    return predicted_food_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "def get_classification_report(predicted_food_labels):    \n",
    "    cm = confusion_matrix(test_food_labels, predicted_food_labels)\n",
    "    print('Confusion Matrix', cm)\n",
    "    print(classification_report(test_food_labels, predicted_food_labels))\n",
    "    print('Accuracy Score', accuracy_score(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[19  3  8]\n",
      " [ 0 26  4]\n",
      " [ 1  5 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.63      0.76        30\n",
      "           1       0.76      0.87      0.81        30\n",
      "           2       0.67      0.80      0.73        30\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        90\n",
      "   macro avg       0.79      0.77      0.77        90\n",
      "weighted avg       0.79      0.77      0.77        90\n",
      "\n",
      "Accuracy Score 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[18  4  8]\n",
      " [ 0 27  3]\n",
      " [ 0  7 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75        30\n",
      "           1       0.71      0.90      0.79        30\n",
      "           2       0.68      0.77      0.72        30\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        90\n",
      "   macro avg       0.80      0.76      0.75        90\n",
      "weighted avg       0.80      0.76      0.75        90\n",
      "\n",
      "Accuracy Score 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 10 #number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[15  5 10]\n",
      " [ 0 26  4]\n",
      " [ 0  8 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        30\n",
      "           1       0.67      0.87      0.75        30\n",
      "           2       0.61      0.73      0.67        30\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        90\n",
      "   macro avg       0.76      0.70      0.70        90\n",
      "weighted avg       0.76      0.70      0.70        90\n",
      "\n",
      "Accuracy Score 0.7\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 15 #number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[13  5 12]\n",
      " [ 0 26  4]\n",
      " [ 0  8 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60        30\n",
      "           1       0.67      0.87      0.75        30\n",
      "           2       0.58      0.73      0.65        30\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        90\n",
      "   macro avg       0.75      0.68      0.67        90\n",
      "weighted avg       0.75      0.68      0.67        90\n",
      "\n",
      "Accuracy Score 0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 20 #number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[11  7 12]\n",
      " [ 0 26  4]\n",
      " [ 0 10 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54        30\n",
      "           1       0.60      0.87      0.71        30\n",
      "           2       0.56      0.67      0.61        30\n",
      "\n",
      "   micro avg       0.63      0.63      0.63        90\n",
      "   macro avg       0.72      0.63      0.62        90\n",
      "weighted avg       0.72      0.63      0.62        90\n",
      "\n",
      "Accuracy Score 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 25 #number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier with num_nearest_neighbours = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[ 9  8 13]\n",
      " [ 0 25  5]\n",
      " [ 0 10 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46        30\n",
      "           1       0.58      0.83      0.68        30\n",
      "           2       0.53      0.67      0.59        30\n",
      "\n",
      "   micro avg       0.60      0.60      0.60        90\n",
      "   macro avg       0.70      0.60      0.58        90\n",
      "weighted avg       0.70      0.60      0.58        90\n",
      "\n",
      "Accuracy Score 0.6\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 30 #number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_knn = get_predicted_labels(knn)\n",
    "get_classification_report(predicted_food_labels_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(C = 50, #see slide 32 in week 4 lecture slides\n",
    "                            kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food label:  [1]\n"
     ]
    }
   ],
   "source": [
    "test_file_name = ['FoodImages/Test/Pasta/pasta35.jpg']\n",
    "word_histograms = dictionary.create_word_histograms(test_file_name)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms)\n",
    "print('Food label: ', predicted_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  5 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.77      0.77      0.77        30\n",
      "           2       0.73      0.80      0.76        30\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        90\n",
      "   macro avg       0.82      0.81      0.81        90\n",
      "weighted avg       0.82      0.81      0.81        90\n",
      "\n",
      "Accuracy Score 0.8111111111111111\n"
     ]
    }
   ],
   "source": [
    "predicted_food_labels_svm = get_predicted_labels(svm_classifier)\n",
    "get_classification_report(predicted_food_labels_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[23  3  4]\n",
      " [ 0 23  7]\n",
      " [ 1  6 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85        30\n",
      "           1       0.72      0.77      0.74        30\n",
      "           2       0.68      0.77      0.72        30\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        90\n",
      "   macro avg       0.78      0.77      0.77        90\n",
      "weighted avg       0.78      0.77      0.77        90\n",
      "\n",
      "Accuracy Score 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C = 10, #see slide 32 in week 4 lecture slides\n",
    "                            kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_svm = get_predicted_labels(svm_classifier)\n",
    "get_classification_report(predicted_food_labels_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with C = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[26  2  2]\n",
      " [ 0 22  8]\n",
      " [ 1  4 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.79      0.73      0.76        30\n",
      "           2       0.71      0.83      0.77        30\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        90\n",
      "   macro avg       0.82      0.81      0.81        90\n",
      "weighted avg       0.82      0.81      0.81        90\n",
      "\n",
      "Accuracy Score 0.8111111111111111\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C = 20, #see slide 32 in week 4 lecture slides\n",
    "                            kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_svm = get_predicted_labels(svm_classifier)\n",
    "get_classification_report(predicted_food_labels_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with C = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[26  2  2]\n",
      " [ 0 22  8]\n",
      " [ 1  3 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.81      0.73      0.77        30\n",
      "           2       0.72      0.87      0.79        30\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        90\n",
      "   macro avg       0.83      0.82      0.82        90\n",
      "weighted avg       0.83      0.82      0.82        90\n",
      "\n",
      "Accuracy Score 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C = 30, #see slide 32 in week 4 lecture slides\n",
    "                            kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_svm = get_predicted_labels(svm_classifier)\n",
    "get_classification_report(predicted_food_labels_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with C = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  5 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.77      0.77      0.77        30\n",
      "           2       0.73      0.80      0.76        30\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        90\n",
      "   macro avg       0.82      0.81      0.81        90\n",
      "weighted avg       0.82      0.81      0.81        90\n",
      "\n",
      "Accuracy Score 0.8111111111111111\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C = 40, #see slide 32 in week 4 lecture slides\n",
    "                            kernel = 'linear') #see slide 35 in week 4 lecture slides\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_svm = get_predicted_labels(svm_classifier)\n",
    "get_classification_report(predicted_food_labels_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=150, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = 150, #weak classifiers\n",
    "                                        random_state = 0)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food label:  [1]\n"
     ]
    }
   ],
   "source": [
    "test_file_name = ['FoodImages/Test/Pasta/pasta35.jpg']\n",
    "word_histograms = dictionary.create_word_histograms(test_file_name)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "print('Food label: ', predicted_food_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier with n_estimator = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[23  1  6]\n",
      " [ 0 16 14]\n",
      " [ 1  6 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85        30\n",
      "           1       0.70      0.53      0.60        30\n",
      "           2       0.53      0.77      0.63        30\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        90\n",
      "   macro avg       0.73      0.69      0.70        90\n",
      "weighted avg       0.73      0.69      0.70        90\n",
      "\n",
      "Accuracy Score 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "predicted_food_labels_ada = get_predicted_labels(adb_classifier)\n",
    "get_classification_report(predicted_food_labels_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier with n_estimator = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[22  1  7]\n",
      " [ 0 18 12]\n",
      " [ 2  7 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        30\n",
      "           1       0.69      0.60      0.64        30\n",
      "           2       0.53      0.70      0.60        30\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        90\n",
      "   macro avg       0.71      0.68      0.69        90\n",
      "weighted avg       0.71      0.68      0.69        90\n",
      "\n",
      "Accuracy Score 0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "adb_classifier = AdaBoostClassifier(n_estimators = 50, #weak classifiers\n",
    "                                        random_state = 0)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_ada = get_predicted_labels(adb_classifier)\n",
    "get_classification_report(predicted_food_labels_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier with n_estimator = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[21  2  7]\n",
      " [ 0 14 16]\n",
      " [ 1  6 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81        30\n",
      "           1       0.64      0.47      0.54        30\n",
      "           2       0.50      0.77      0.61        30\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        90\n",
      "   macro avg       0.70      0.64      0.65        90\n",
      "weighted avg       0.70      0.64      0.65        90\n",
      "\n",
      "Accuracy Score 0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "adb_classifier = AdaBoostClassifier(n_estimators = 100, #weak classifiers\n",
    "                                        random_state = 0)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_ada = get_predicted_labels(adb_classifier)\n",
    "get_classification_report(predicted_food_labels_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier with n_estimator = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[23  1  6]\n",
      " [ 0 16 14]\n",
      " [ 1  6 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85        30\n",
      "           1       0.70      0.53      0.60        30\n",
      "           2       0.53      0.77      0.63        30\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        90\n",
      "   macro avg       0.73      0.69      0.70        90\n",
      "weighted avg       0.73      0.69      0.70        90\n",
      "\n",
      "Accuracy Score 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "adb_classifier = AdaBoostClassifier(n_estimators = 200, #weak classifiers\n",
    "                                        random_state = 0)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_ada = get_predicted_labels(adb_classifier)\n",
    "get_classification_report(predicted_food_labels_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier with n_estimator = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[24  1  5]\n",
      " [ 0 17 13]\n",
      " [ 1  8 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87        30\n",
      "           1       0.65      0.57      0.61        30\n",
      "           2       0.54      0.70      0.61        30\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        90\n",
      "   macro avg       0.72      0.69      0.70        90\n",
      "weighted avg       0.72      0.69      0.70        90\n",
      "\n",
      "Accuracy Score 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "adb_classifier = AdaBoostClassifier(n_estimators = 250, #weak classifiers\n",
    "                                        random_state = 0)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels_ada = get_predicted_labels(adb_classifier)\n",
    "get_classification_report(predicted_food_labels_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
